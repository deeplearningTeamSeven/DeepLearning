{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"YOLOv5.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"saakCjScUEiE","executionInfo":{"status":"ok","timestamp":1630477717047,"user_tz":-540,"elapsed":26171,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"0a978061-11bf-4760-9e54-c429ea44a9d1"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4TWdMBpUUlF","executionInfo":{"status":"ok","timestamp":1630477717049,"user_tz":-540,"elapsed":13,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"75c94b28-4354-4199-be7e-b0825c88b3b7"},"source":["cd /content/drive/MyDrive/YOLOv5"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/YOLOv5\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-b-GV7JmUpBt","executionInfo":{"status":"ok","timestamp":1630377971241,"user_tz":-540,"elapsed":24,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"4513b3cf-e2b1-4f8c-9342-894a6b540c91"},"source":["!git clone https://github.com/ultralytics/yolov5.git"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'yolov5' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-gL52mxWVJbs","executionInfo":{"status":"ok","timestamp":1630477720169,"user_tz":-540,"elapsed":414,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"bedde2f8-379e-4eb1-acf8-3cec54799d1c"},"source":["cd yolov5/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/YOLOv5/yolov5\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJrUE77AUuPz","executionInfo":{"status":"ok","timestamp":1630477896448,"user_tz":-540,"elapsed":3109,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"f8e6dad8-9a8c-4f27-f0cf-d476b20dd9b0"},"source":["!pip install -r requirements.txt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n","Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (8.3.1)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (5.4.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.4.1)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.9.0+cu102)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.10.0+cu102)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (4.62.0)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (2.6.0)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (0.11.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.1.5)\n","Collecting thop\n","  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (3.7.4.3)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.34.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.3.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (57.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.8.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.37.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.5)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.39.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.6.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.12.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.17.3)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 20)) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.15.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.2.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.7.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.6.4)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.5.0)\n","Installing collected packages: thop\n","Successfully installed thop-0.0.31.post2005241907\n"]}]},{"cell_type":"code","metadata":{"id":"oRrYhYmmXs6r"},"source":["pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gzjou9SfaSdm"},"source":["# from utils.autoanchor import *;_=kmean_anchors(path='/content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml', n=100, img_size=480, thr=4.0, gen=1000, verbose=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xhUyWfTvQ9F"},"source":["!pip install wandb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1jcTdY6uV5cB","outputId":"dc307a7e-bd16-464e-f3db-b69334782759"},"source":["!python train.py --batch 16 --epochs 100 --data /content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml --cfg ./models/yolov5m.yaml --weights yolov5m.pt"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=./models/yolov5m.yaml, data=/content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=100, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 2021-8-21 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mleeyumin\u001b[0m (use `wandb login --relogin` to force relogin)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.0\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdevout-water-2\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/leeyumin/YOLOv5\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/leeyumin/YOLOv5/runs/2pux48wq\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/drive/My Drive/YOLOv5/yolov5/wandb/run-20210821_130752-2pux48wq\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n","\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5m.pt to yolov5m.pt...\n","100% 41.1M/41.1M [00:02<00:00, 16.8MB/s]\n","\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      5280  models.common.Focus                     [3, 48, 3]                    \n","  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n","  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n","  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n","  4                -1  6    629760  models.common.C3                        [192, 192, 6]                 \n","  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n","  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n","  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n","  8                -1  1   1476864  models.common.SPP                       [768, 768, [5, 9, 13]]        \n","  9                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n"," 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n"," 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n"," 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 24      [17, 20, 23]  1    424305  models.yolo.Detect                      [100, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n","Model Summary: 391 layers, 21456465 parameters, 21456465 gradients, 51.7 GFLOPs\n","\n","Transferred 498/506 items from yolov5m.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 83 weight, 86 weight (no decay), 86 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_train' images and labels...8000 found, 0 missing, 0 empty, 0 corrupted: 100% 8000/8000 [00:27<00:00, 288.71it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/YOLOv5/image_train.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_valid.cache' images and labels... 2000 found, 0 missing, 0 empty, 0 corrupted: 100% 2000/2000 [00:00<?, ?it/s]\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Plotting labels... \n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.16, Best Possible Recall (BPR) = 0.9998\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to runs/train/exp4\n","Starting training for 100 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      0/99     6.04G   0.05367   0.02511    0.1048        43       640: 100% 500/500 [42:59<00:00,  5.16s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [03:49<00:00,  3.65s/it]\n","                 all       2000       2358     0.0109      0.177     0.0162     0.0114\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      1/99     9.86G   0.03639   0.01983   0.09802        46       640: 100% 500/500 [40:01<00:00,  4.80s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [03:03<00:00,  2.92s/it]\n","                 all       2000       2358     0.0435      0.164     0.0329     0.0248\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      2/99     9.86G   0.03816   0.01953   0.09252        42       640: 100% 500/500 [40:02<00:00,  4.81s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [03:07<00:00,  2.97s/it]\n","                 all       2000       2358     0.0513      0.181     0.0384     0.0252\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      3/99     9.86G   0.03893   0.02067   0.08692        50       640: 100% 500/500 [39:47<00:00,  4.77s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [03:06<00:00,  2.96s/it]\n","                 all       2000       2358     0.0756      0.312     0.0807     0.0501\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      4/99     9.86G   0.03771   0.02028   0.08138        49       640: 100% 500/500 [39:29<00:00,  4.74s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [03:03<00:00,  2.91s/it]\n","                 all       2000       2358      0.265      0.287       0.16      0.105\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      5/99     9.86G   0.03748    0.0211   0.07736        47       640:  48% 242/500 [19:40<23:02,  5.36s/it]"]}]},{"cell_type":"code","metadata":{"id":"Wi91w3SZYIba","executionInfo":{"status":"ok","timestamp":1630505057247,"user_tz":-540,"elapsed":5,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}}},"source":["# batch 64로 하니까 RuntimeError: CUDA out of memory 발생해서 16으로 줄이니까 제대로 돌아감"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FzMN7yX3rCzx"},"source":["학습이 끊어진 후 재학습\n","--resume last.pt의 경로"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3F4Nlw5TqFy","outputId":"da78aa35-78b2-4a63-8faa-6debace755be"},"source":["!python train.py --batch 16 --epochs 100 --data /content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml --cfg ./models/yolov5m.yaml --weights yolov5m.pt --resume /content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=./models/yolov5m.yaml, data=/content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=100, batch_size=16, imgsz=640, rect=False, resume=/content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0\n","\u001b[34m\u001b[1mgithub: \u001b[0mCommand 'git fetch && git config --get remote.origin.url' timed out after 5 seconds\n","Resuming training from /content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt\n","YOLOv5 🚀 v5.0-375-gd1182c4 torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      5280  models.common.Focus                     [3, 48, 3]                    \n","  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n","  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n","  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n","  4                -1  6    629760  models.common.C3                        [192, 192, 6]                 \n","  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n","  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n","  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n","  8                -1  1   1476864  models.common.SPP                       [768, 768, [5, 9, 13]]        \n","  9                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n"," 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n"," 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n"," 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 24      [17, 20, 23]  1    424305  models.yolo.Detect                      [100, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n","Model Summary: 391 layers, 21456465 parameters, 21456465 gradients, 51.7 GFLOPs\n","\n","Transferred 506/506 items from /content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 83 weight, 86 weight (no decay), 86 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_train.cache' images and labels... 8000 found, 0 missing, 0 empty, 0 corrupted: 100% 8000/8000 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_valid.cache' images and labels... 2000 found, 0 missing, 0 empty, 0 corrupted: 100% 2000/2000 [00:00<?, ?it/s]\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to runs/train/exp4\n","Starting training for 100 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      5/99     6.35G   0.03555    0.0201   0.07614        43       640: 100% 500/500 [1:18:34<00:00,  9.43s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [16:54<00:00, 16.10s/it]\n","                 all       2000       2358      0.261      0.316      0.202      0.136\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      6/99     10.2G   0.03575   0.02002   0.07216        46       640: 100% 500/500 [26:56<00:00,  3.23s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:11<00:00,  2.09s/it]\n","                 all       2000       2358      0.211      0.368        0.2      0.136\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      7/99     10.2G   0.03463   0.01945   0.06864        42       640: 100% 500/500 [27:13<00:00,  3.27s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:11<00:00,  2.08s/it]\n","                 all       2000       2358      0.308       0.35      0.245      0.163\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      8/99     10.2G   0.03488    0.0195   0.06681        50       640: 100% 500/500 [27:19<00:00,  3.28s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:11<00:00,  2.09s/it]\n","                 all       2000       2358      0.268      0.432      0.277      0.189\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      9/99     10.2G   0.03483   0.01915   0.06399        49       640: 100% 500/500 [26:56<00:00,  3.23s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:13<00:00,  2.11s/it]\n","                 all       2000       2358      0.336       0.38      0.298      0.202\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     10/99     10.2G   0.03581   0.01955   0.06373        56       640: 100% 500/500 [27:10<00:00,  3.26s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:10<00:00,  2.08s/it]\n","                 all       2000       2358      0.334      0.391      0.301      0.203\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     11/99     10.2G   0.03467   0.01916   0.05964        52       640: 100% 500/500 [27:02<00:00,  3.25s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:12<00:00,  2.10s/it]\n","                 all       2000       2358       0.32      0.445      0.346      0.233\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     12/99     10.2G    0.0342   0.01887   0.05848        48       640: 100% 500/500 [27:02<00:00,  3.24s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:14<00:00,  2.13s/it]\n","                 all       2000       2358      0.356      0.409      0.342       0.23\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     13/99     10.2G   0.03391   0.01878     0.058        56       640: 100% 500/500 [27:25<00:00,  3.29s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:14<00:00,  2.13s/it]\n","                 all       2000       2358      0.335      0.442       0.36       0.25\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     14/99     10.2G   0.03392   0.01863   0.05497        49       640: 100% 500/500 [27:19<00:00,  3.28s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:12<00:00,  2.11s/it]\n","                 all       2000       2358      0.374      0.429      0.371      0.253\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     15/99     10.2G   0.03358   0.01875    0.0531        50       640: 100% 500/500 [27:19<00:00,  3.28s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:12<00:00,  2.11s/it]\n","                 all       2000       2358      0.469      0.447      0.426      0.298\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     16/99     10.2G   0.03338   0.01894   0.05197        42       640:  59% 297/500 [16:20<08:34,  2.54s/it]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0whPdtc5T0zi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7112ae44-02b2-437d-c976-a1d1a5c181b4"},"source":["!python train.py --batch 16 --epochs 100 --data /content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml --cfg ./models/yolov5m.yaml --weights yolov5m.pt --resume /content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=./models/yolov5m.yaml, data=/content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=100, batch_size=16, imgsz=640, rect=False, resume=/content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0\n","\u001b[34m\u001b[1mgithub: \u001b[0mCommand 'git fetch && git config --get remote.origin.url' timed out after 5 seconds\n","Resuming training from /content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt\n","YOLOv5 🚀 2021-8-21 torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","remote: Enumerating objects: 10, done.\u001b[K\n","remote: Counting objects: 100% (10/10), done.\u001b[K\n","remote: Compressing objects: 100% (7/7), done.\u001b[K\n","remote: Total 10 (delta 3), reused 10 (delta 3), pack-reused 0\u001b[K\n","Unpacking objects: 100% (10/10), done.\n","From https://github.com/ultralytics/yolov5\n","   f83e820..b3f57e8  new_data_set_loaders -> origin/new_data_set_loaders\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      5280  models.common.Focus                     [3, 48, 3]                    \n","  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n","  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n","  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n","  4                -1  6    629760  models.common.C3                        [192, 192, 6]                 \n","  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n","  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n","  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n","  8                -1  1   1476864  models.common.SPP                       [768, 768, [5, 9, 13]]        \n","  9                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n"," 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n"," 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n"," 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 24      [17, 20, 23]  1    424305  models.yolo.Detect                      [100, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n","Model Summary: 391 layers, 21456465 parameters, 21456465 gradients, 51.7 GFLOPs\n","\n","Transferred 506/506 items from /content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 83 weight, 86 weight (no decay), 86 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_train.cache' images and labels... 8000 found, 0 missing, 0 empty, 0 corrupted: 100% 8000/8000 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_valid.cache' images and labels... 2000 found, 0 missing, 0 empty, 0 corrupted: 100% 2000/2000 [00:00<?, ?it/s]\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to runs/train/exp4\n","Starting training for 100 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     16/99     6.35G   0.03315   0.01836   0.05026        43       640: 100% 500/500 [1:14:07<00:00,  8.89s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [20:54<00:00, 19.91s/it]\n","                 all       2000       2358      0.389      0.463      0.397      0.285\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     17/99     10.2G   0.03376    0.0182   0.04909        46       640: 100% 500/500 [26:38<00:00,  3.20s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:10<00:00,  2.08s/it]\n","                 all       2000       2358      0.382      0.534      0.441      0.315\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     18/99     10.2G    0.0329   0.01793   0.04806        42       640: 100% 500/500 [26:48<00:00,  3.22s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:11<00:00,  2.09s/it]\n","                 all       2000       2358      0.429      0.432      0.421      0.298\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     19/99     10.2G   0.03298   0.01802   0.04756        50       640: 100% 500/500 [26:58<00:00,  3.24s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:11<00:00,  2.08s/it]\n","                 all       2000       2358      0.384      0.426       0.37      0.262\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     20/99     10.2G   0.03216   0.01776   0.04595        49       640: 100% 500/500 [26:39<00:00,  3.20s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:08<00:00,  2.05s/it]\n","                 all       2000       2358      0.475      0.481      0.469      0.341\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     21/99     10.2G   0.03346   0.01781   0.04466        56       640: 100% 500/500 [26:43<00:00,  3.21s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:10<00:00,  2.06s/it]\n","                 all       2000       2358      0.463      0.524      0.481      0.347\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     22/99     10.2G   0.03278   0.01757   0.04212        52       640: 100% 500/500 [26:32<00:00,  3.18s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:10<00:00,  2.08s/it]\n","                 all       2000       2358      0.464      0.535      0.511      0.373\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     23/99     10.2G   0.03207   0.01726   0.04104        48       640: 100% 500/500 [26:33<00:00,  3.19s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:13<00:00,  2.12s/it]\n","                 all       2000       2358      0.452       0.56      0.523      0.382\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     24/99     10.2G   0.03227   0.01691   0.03946        56       640: 100% 500/500 [26:50<00:00,  3.22s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:09<00:00,  2.05s/it]\n","                 all       2000       2358      0.575      0.531       0.56      0.419\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     25/99     10.2G   0.03219   0.01694   0.03745        49       640: 100% 500/500 [26:49<00:00,  3.22s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:10<00:00,  2.08s/it]\n","                 all       2000       2358      0.547      0.538      0.554      0.411\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     26/99     10.2G   0.03273   0.01692   0.03636        50       640: 100% 500/500 [26:50<00:00,  3.22s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:12<00:00,  2.10s/it]\n","                 all       2000       2358      0.565      0.547      0.574      0.422\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     27/99     10.2G   0.03162   0.01714   0.03825        44       640: 100% 500/500 [26:39<00:00,  3.20s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:10<00:00,  2.06s/it]\n","                 all       2000       2358      0.536      0.519      0.532      0.397\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     28/99     10.2G   0.03177   0.01778   0.04049        56       640:  66% 329/500 [17:45<07:42,  2.70s/it]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xJG5IDKixSyg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630053729911,"user_tz":-540,"elapsed":6187660,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"3285baeb-c508-405d-e4b4-5a959bebfcba"},"source":["!python train.py --batch 16 --epochs 50 --data /content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml --cfg ./models/yolov5m.yaml --weights yolov5m.pt --resume /content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=./models/yolov5m.yaml, data=/content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=100, batch_size=16, imgsz=640, rect=False, resume=/content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0\n","\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ WARNING: code is out of date by 5 commits. Use 'git pull' to update or 'git clone https://github.com/ultralytics/yolov5' to download latest.\n","Resuming training from /content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt\n","YOLOv5 🚀 2021-8-21 torch 1.9.0+cu102 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      5280  models.common.Focus                     [3, 48, 3]                    \n","  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n","  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n","  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n","  4                -1  6    629760  models.common.C3                        [192, 192, 6]                 \n","  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n","  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n","  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n","  8                -1  1   1476864  models.common.SPP                       [768, 768, [5, 9, 13]]        \n","  9                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n"," 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n"," 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n"," 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 24      [17, 20, 23]  1    424305  models.yolo.Detect                      [100, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n","Model Summary: 391 layers, 21456465 parameters, 21456465 gradients, 51.7 GFLOPs\n","\n","Transferred 506/506 items from /content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 83 weight, 86 weight (no decay), 86 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_train.cache' images and labels... 8000 found, 0 missing, 0 empty, 0 corrupted: 100% 8000/8000 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_valid.cache' images and labels... 2000 found, 0 missing, 0 empty, 0 corrupted: 100% 2000/2000 [00:00<?, ?it/s]\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to runs/train/exp4\n","Starting training for 100 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     97/99      6.1G   0.01861   0.01028  0.006785        43       640: 100% 500/500 [31:42<00:00,  3.80s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:31<00:00,  2.41s/it]\n","                 all       2000       2358      0.744       0.71      0.747      0.608\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     98/99     9.92G   0.01842   0.01001  0.006111        46       640: 100% 500/500 [31:04<00:00,  3.73s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:32<00:00,  2.42s/it]\n","                 all       2000       2358      0.758      0.697      0.747      0.608\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     99/99     9.92G   0.01867  0.009815  0.005834        42       640: 100% 500/500 [31:40<00:00,  3.80s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:35<00:00,  2.47s/it]\n","                 all       2000       2358      0.763      0.693      0.746      0.607\n","\n","3 epochs completed in 1.707 hours.\n","Optimizer stripped from runs/train/exp4/weights/last.pt, 43.3MB\n","Optimizer stripped from runs/train/exp4/weights/best.pt, 43.3MB\n","Results saved to \u001b[1mruns/train/exp4\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"78g4jJ54W3yF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d26b892e-10c1-4d06-a409-600c4722ae5c"},"source":["!python train.py --batch 16 --epochs 50 --data /content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml --cfg ./models/yolov5m.yaml --weights /content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt, cfg=./models/yolov5m.yaml, data=/content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0\n","\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ WARNING: code is out of date by 5 commits. Use 'git pull' to update or 'git clone https://github.com/ultralytics/yolov5' to download latest.\n","YOLOv5 🚀 2021-8-21 torch 1.9.0+cu102 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      5280  models.common.Focus                     [3, 48, 3]                    \n","  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n","  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n","  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n","  4                -1  6    629760  models.common.C3                        [192, 192, 6]                 \n","  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n","  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n","  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n","  8                -1  1   1476864  models.common.SPP                       [768, 768, [5, 9, 13]]        \n","  9                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n"," 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n"," 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n"," 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 24      [17, 20, 23]  1    424305  models.yolo.Detect                      [100, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n","Model Summary: 391 layers, 21456465 parameters, 21456465 gradients, 51.7 GFLOPs\n","\n","Transferred 504/506 items from /content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp4/weights/last.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 83 weight, 86 weight (no decay), 86 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_train.cache' images and labels... 8000 found, 0 missing, 0 empty, 0 corrupted: 100% 8000/8000 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_valid.cache' images and labels... 2000 found, 0 missing, 0 empty, 0 corrupted: 100% 2000/2000 [00:00<?, ?it/s]\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Plotting labels... \n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.16, Best Possible Recall (BPR) = 0.9998\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to runs/train/exp\n","Starting training for 50 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      0/49     6.04G    0.0145  0.009129  0.005089        43       640: 100% 500/500 [30:45<00:00,  3.69s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:29<00:00,  2.38s/it]\n","                 all       2000       2358      0.737      0.704      0.733       0.58\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      1/49     9.86G    0.0214   0.00967  0.005644        46       640: 100% 500/500 [31:18<00:00,  3.76s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:31<00:00,  2.40s/it]\n","                 all       2000       2358      0.719      0.717      0.726      0.564\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      2/49     9.86G   0.02869   0.01076   0.00844        42       640: 100% 500/500 [31:38<00:00,  3.80s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:33<00:00,  2.43s/it]\n","                 all       2000       2358      0.633       0.63       0.63      0.449\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      3/49     9.86G   0.03338   0.01362   0.01679        50       640: 100% 500/500 [31:42<00:00,  3.80s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:32<00:00,  2.42s/it]\n","                 all       2000       2358      0.602      0.565      0.594      0.419\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      4/49     9.86G   0.03237   0.01596   0.02764        49       640: 100% 500/500 [31:33<00:00,  3.79s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:30<00:00,  2.39s/it]\n","                 all       2000       2358      0.402      0.508      0.429      0.294\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      5/49     9.86G    0.0323   0.01878   0.04244        56       640: 100% 500/500 [31:37<00:00,  3.80s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:33<00:00,  2.44s/it]\n","                 all       2000       2358      0.515      0.443      0.466      0.314\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      6/49     9.86G   0.03104   0.01758   0.03383        52       640: 100% 500/500 [31:14<00:00,  3.75s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:30<00:00,  2.39s/it]\n","                 all       2000       2358      0.472      0.506      0.489      0.346\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      7/49     9.86G   0.03037   0.01708   0.03333        48       640: 100% 500/500 [31:26<00:00,  3.77s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:33<00:00,  2.43s/it]\n","                 all       2000       2358      0.492      0.444      0.448      0.315\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      8/49     9.86G   0.03103   0.01673   0.03083        56       640: 100% 500/500 [31:46<00:00,  3.81s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:33<00:00,  2.44s/it]\n","                 all       2000       2358      0.537       0.55      0.556      0.395\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","      9/49     9.86G   0.03046   0.01629   0.02642        49       640: 100% 500/500 [31:38<00:00,  3.80s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 63/63 [02:28<00:00,  2.36s/it]\n","                 all       2000       2358      0.567      0.558      0.573      0.411\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     10/49     9.86G   0.03099   0.01609   0.02515        46       640:  72% 358/500 [22:27<06:51,  2.90s/it]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-82_39hlDM1c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630295625171,"user_tz":-540,"elapsed":6380,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"f8cb1876-ec8f-46e7-9d68-74a08b729d07"},"source":["!python detect.py --source ./test.jpeg --weights runs/train/exp4/weights/best.pt --conf 0.1 --line-thickness 5"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp4/weights/best.pt'], source=./test.jpeg, imgsz=640, conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=static, name=, exist_ok=True, line_thickness=5, hide_labels=False, hide_conf=False, half=False\n","YOLOv5 🚀 2021-8-21 torch 1.9.0+cu102 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n","\n","Fusing layers... \n","Model Summary: 308 layers, 21437697 parameters, 0 gradients, 51.6 GFLOPs\n","===================\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n","===================\n","===================\n","[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n","===================\n","image 1/1 /content/drive/My Drive/YOLOv5/yolov5_100class/test.jpeg: 5!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","tensor([[[7.40988e+00, 8.90630e+00, 1.64109e+01,  ..., 1.09092e-02, 8.70901e-03, 3.48445e-03],\n","         [1.42164e+01, 9.28701e+00, 2.93364e+01,  ..., 9.12783e-03, 1.00173e-02, 3.54792e-03],\n","         [1.95535e+01, 8.69201e+00, 3.45901e+01,  ..., 8.89664e-03, 1.11760e-02, 3.43039e-03],\n","         ...,\n","         [5.62818e+02, 4.40483e+02, 1.59171e+02,  ..., 4.63609e-02, 1.98931e-04, 6.15991e-05],\n","         [5.84592e+02, 4.44105e+02, 1.14217e+02,  ..., 2.12951e-01, 1.28134e-04, 7.32734e-05],\n","         [6.12419e+02, 4.48669e+02, 9.75632e+01,  ..., 5.12202e-01, 3.07115e-04, 9.57020e-05]]], device='cuda:0')\n","5!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","[tensor([[3.16133e+01, 2.67018e+01, 3.15586e+02, 2.22440e+02, 1.76467e-01, 4.30000e+01],\n","        [1.19981e+02, 1.24558e+02, 6.35958e+02, 3.96716e+02, 1.54428e-01, 2.40000e+01]], device='cuda:0')]\n","!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","//////////////////////////\n","tensor([[3.16133e+01, 2.67018e+01, 3.15586e+02, 2.22440e+02, 1.76467e-01, 4.30000e+01],\n","        [1.19981e+02, 1.24558e+02, 6.35958e+02, 3.96716e+02, 1.54428e-01, 2.40000e+01]], device='cuda:0')\n","//////////////////////////\n","aaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n","24 0.15\n","aaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n","Traceback (most recent call last):\n","  File \"detect.py\", line 257, in <module>\n","    main(opt)\n","  File \"detect.py\", line 252, in main\n","    run(**vars(opt))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"detect.py\", line 178, in run\n","    plot_one_box(xyxy, im0, label=label, color=colors(c, True), line_thickness=line_thickness)\n","TypeError: plot_one_box() got an unexpected keyword argument 'line_thickness'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v2HPRbrkKdKw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630372963346,"user_tz":-540,"elapsed":32520,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"6384e38f-8612-41e7-8939-4c96b172d774"},"source":["!python train.py --batch 32 --epochs 300 --data /content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml --cfg ./models/yolov5l.yaml --weights \"\"\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=./models/yolov5l.yaml, data=/content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=300, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=30\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 2021-8-31 torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      7040  models.common.Focus                     [3, 64, 3]                    \n","  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  4                -1  9   1611264  models.common.C3                        [256, 256, 9]                 \n","  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n","  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n","  8                -1  1   2624512  models.common.SPP                       [1024, 1024, [5, 9, 13]]      \n","  9                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n"," 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n"," 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n"," 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n"," 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n"," 24      [17, 20, 23]  1   1313940  models.yolo.Detect                      [239, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n","Model Summary: 499 layers, 47912980 parameters, 47912980 gradients, 118.3 GFLOPs\n","\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 107 weight, 110 weight (no decay), 110 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_train' images and labels...0 found, 541 missing, 0 empty, 0 corrupted:   1% 541/38240 [00:22<26:15, 23.93it/s]  \n","Traceback (most recent call last):\n","  File \"/content/drive/My Drive/YOLOv5/yolov5/utils/datasets.py\", line 406, in __init__\n","    cache, exists = np.load(cache_path, allow_pickle=True).item(), True  # load dict\n","  File \"/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\", line 416, in load\n","    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/YOLOv5/image_train.cache'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 733, in next\n","    item = self._items.popleft()\n","IndexError: pop from an empty deque\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"train.py\", line 610, in <module>\n","    main(opt)\n","  File \"train.py\", line 508, in main\n","    train(opt.hyp, opt, device)\n","  File \"train.py\", line 209, in train\n","    prefix=colorstr('train: '))\n","  File \"/content/drive/My Drive/YOLOv5/yolov5/utils/datasets.py\", line 107, in create_dataloader\n","    prefix=prefix)\n","  File \"/content/drive/My Drive/YOLOv5/yolov5/utils/datasets.py\", line 409, in __init__\n","    cache, exists = self.cache_labels(cache_path, prefix), False  # cache\n","  File \"/content/drive/My Drive/YOLOv5/yolov5/utils/datasets.py\", line 492, in cache_labels\n","    for im_file, l, shape, segments, nm_f, nf_f, ne_f, nc_f, msg in pbar:\n","  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1185, in __iter__\n","    for obj in iterable:\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 737, in next\n","    self._cond.wait(timeout)\n","  File \"/usr/lib/python3.7/threading.py\", line 296, in wait\n","    waiter.acquire()\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LeHvsZJPv6dy","executionInfo":{"status":"ok","timestamp":1630372113169,"user_tz":-540,"elapsed":273,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"d1756e1c-fe9f-48e6-caac-b34d1f2a41c6"},"source":["import numpy as np\n","\n","np.arange(0,239)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n","        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n","        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n","        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n","        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n","        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n","        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n","        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n","       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n","       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n","       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n","       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n","       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n","       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n","       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n","       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n","       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n","       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n","       234, 235, 236, 237, 238])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"o9Z87rNJABMR","executionInfo":{"status":"ok","timestamp":1630376303886,"user_tz":-540,"elapsed":259,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"de2866c9-be63-4b88-f37f-74d58bc32aa9"},"source":["pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/My Drive/YOLOv5/yolov5_100class'"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DbLxivLv9u0","executionInfo":{"status":"ok","timestamp":1630398086270,"user_tz":-540,"elapsed":854801,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"acb7d6bf-d899-4cf1-d5db-da84212d7546"},"source":["!python train.py --batch 32 --epochs 300 --data /content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml --cfg ./models/yolov5l.yaml --weights yolov5l.pt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l.pt, cfg=./models/yolov5l.yaml, data=/content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=300, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=30\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 2021-8-31 torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      7040  models.common.Focus                     [3, 64, 3]                    \n","  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  4                -1  9   1611264  models.common.C3                        [256, 256, 9]                 \n","  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n","  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n","  8                -1  1   2624512  models.common.SPP                       [1024, 1024, [5, 9, 13]]      \n","  9                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n"," 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n"," 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n"," 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n"," 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n"," 24      [17, 20, 23]  1   1313940  models.yolo.Detect                      [239, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n","Model Summary: 499 layers, 47912980 parameters, 47912980 gradients, 118.3 GFLOPs\n","\n","Transferred 642/650 items from yolov5l.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 107 weight, 110 weight (no decay), 110 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_train_239' images and labels...38240 found, 0 missing, 0 empty, 2 corrupted: 100% 38240/38240 [4:24:40<00:00,  2.41it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/YOLOv5/data/images/train/A020143XX_14147.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/YOLOv5/data/images/train/B140709XX_31783.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/YOLOv5/image_train_239.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_valid_239' images and labels...9560 found, 0 missing, 0 empty, 1 corrupted: 100% 9560/9560 [1:09:21<00:00,  2.30it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/YOLOv5/data/images/valid/A270104XX_14916.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/YOLOv5/image_valid_239.cache\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Plotting labels... \n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.98, Best Possible Recall (BPR) = 0.9999\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp6\u001b[0m\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","  0% 0/1195 [00:00<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"train.py\", line 610, in <module>\n","    main(opt)\n","  File \"train.py\", line 508, in main\n","    train(opt.hyp, opt, device)\n","  File \"train.py\", line 311, in train\n","    pred = model(imgs)  # forward\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/My Drive/YOLOv5/yolov5/models/yolo.py\", line 123, in forward\n","    return self.forward_once(x, profile, visualize)  # single-scale inference, train\n","  File \"/content/drive/My Drive/YOLOv5/yolov5/models/yolo.py\", line 155, in forward_once\n","    x = m(x)  # run\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/My Drive/YOLOv5/yolov5/models/common.py\", line 137, in forward\n","    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 139, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/My Drive/YOLOv5/yolov5/models/common.py\", line 103, in forward\n","    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/content/drive/My Drive/YOLOv5/yolov5/models/common.py\", line 45, in forward\n","    return self.act(self.bn(self.conv(x)))\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 443, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 440, in _conv_forward\n","    self.padding, self.dilation, self.groups)\n","RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n"]}]},{"cell_type":"code","metadata":{"id":"XoFUUquG0Y9o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630405182266,"user_tz":-540,"elapsed":2652560,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"ed17d959-c85d-4e34-bfba-302ca714223c"},"source":["!python train.py --batch 16 --epochs 300 --data /content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml --cfg ./models/yolov5l.yaml --weights yolov5l.pt\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l.pt, cfg=./models/yolov5l.yaml, data=/content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=300, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=30\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 2021-8-31 torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      7040  models.common.Focus                     [3, 64, 3]                    \n","  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n","  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  4                -1  9   1611264  models.common.C3                        [256, 256, 9]                 \n","  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n","  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n","  8                -1  1   2624512  models.common.SPP                       [1024, 1024, [5, 9, 13]]      \n","  9                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n"," 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n"," 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n"," 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n"," 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n"," 24      [17, 20, 23]  1   1313940  models.yolo.Detect                      [239, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n","Model Summary: 499 layers, 47912980 parameters, 47912980 gradients, 118.3 GFLOPs\n","\n","Transferred 642/650 items from yolov5l.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 107 weight, 110 weight (no decay), 110 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_train_239.cache' images and labels... 38240 found, 0 missing, 0 empty, 2 corrupted: 100% 38240/38240 [00:00<?, ?it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/YOLOv5/data/images/train/A020143XX_14147.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/YOLOv5/data/images/train/B140709XX_31783.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_train_239.cache' images and labels... 38240 found, 0 missing, 0 empty, 2 corrupted: 100% 38240/38240 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_valid_239.cache' images and labels... 9560 found, 0 missing, 0 empty, 1 corrupted: 100% 9560/9560 [00:00<?, ?it/s]\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/YOLOv5/data/images/valid/A270104XX_14916.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_valid_239.cache' images and labels... 9560 found, 0 missing, 0 empty, 1 corrupted: 100% 9560/9560 [00:00<?, ?it/s]\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Plotting labels... \n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.98, Best Possible Recall (BPR) = 0.9999\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp8\u001b[0m\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     0/299     10.4G   0.05276    0.0255    0.1191        49       640:  27% 651/2390 [1:51:44<4:58:29, 10.30s/it]\n","Traceback (most recent call last):\n","  File \"train.py\", line 610, in <module>\n","    main(opt)\n","  File \"train.py\", line 508, in main\n","    train(opt.hyp, opt, device)\n","  File \"train.py\", line 319, in train\n","    scaler.scale(loss).backward()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 255, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 149, in backward\n","    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W7YGerT3UE9Z","outputId":"1f83aa0d-483e-4d83-d8a6-f08b88c3416c"},"source":["!python train.py --batch 16 --epochs 300 --data /content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml --cfg ./models/yolov5m.yaml --weights yolov5m.pt\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=./models/yolov5m.yaml, data=/content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=300, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=30\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 2021-8-31 torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      5280  models.common.Focus                     [3, 48, 3]                    \n","  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n","  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n","  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n","  4                -1  6    629760  models.common.C3                        [192, 192, 6]                 \n","  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n","  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n","  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n","  8                -1  1   1476864  models.common.SPP                       [768, 768, [5, 9, 13]]        \n","  9                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n"," 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n"," 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n"," 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 24      [17, 20, 23]  1    986004  models.yolo.Detect                      [239, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n","Model Summary: 391 layers, 22018164 parameters, 22018164 gradients, 53.5 GFLOPs\n","\n","Transferred 498/506 items from yolov5m.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 83 weight, 86 weight (no decay), 86 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_train_239.cache' images and labels... 38240 found, 0 missing, 0 empty, 2 corrupted: 100% 38240/38240 [00:00<?, ?it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/YOLOv5/data/images/train/A020143XX_14147.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/YOLOv5/data/images/train/B140709XX_31783.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_train_239.cache' images and labels... 38240 found, 0 missing, 0 empty, 2 corrupted: 100% 38240/38240 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_valid_239.cache' images and labels... 9560 found, 0 missing, 0 empty, 1 corrupted: 100% 9560/9560 [00:00<?, ?it/s]\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/YOLOv5/data/images/valid/A270104XX_14916.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_valid_239.cache' images and labels... 9560 found, 0 missing, 0 empty, 1 corrupted: 100% 9560/9560 [00:00<?, ?it/s]\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Plotting labels... \n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.98, Best Possible Recall (BPR) = 0.9999\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp10\u001b[0m\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     0/299      6.6G   0.03688   0.02152    0.1171        33       640: 100% 2390/2390 [2:11:05<00:00,  3.29s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 299/299 [44:59<00:00,  9.03s/it]\n","                 all       9559      11176    0.00573      0.244    0.00755    0.00605\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     1/299     12.5G   0.02949   0.01828    0.1098        43       640: 100% 2390/2390 [1:52:25<00:00,  2.82s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 299/299 [08:51<00:00,  1.78s/it]\n","                 all       9559      11176      0.245      0.202     0.0365     0.0268\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     2/299     12.5G   0.03318   0.01897    0.1008        38       640: 100% 2390/2390 [1:51:59<00:00,  2.81s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 299/299 [08:58<00:00,  1.80s/it]\n","                 all       9559      11176      0.172      0.298     0.0714     0.0492\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     3/299     12.5G   0.03405   0.01953   0.09337        29       640: 100% 2390/2390 [1:52:11<00:00,  2.82s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 299/299 [08:52<00:00,  1.78s/it]\n","                 all       9559      11176      0.283      0.284      0.133     0.0942\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     4/299     12.5G   0.03347   0.01933   0.08811        36       640: 100% 2390/2390 [1:52:45<00:00,  2.83s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 299/299 [08:58<00:00,  1.80s/it]\n","                 all       9559      11176      0.302      0.321      0.179       0.13\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     5/299     12.5G   0.03267   0.01906   0.08315        35       640: 100% 2390/2390 [1:52:39<00:00,  2.83s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 299/299 [08:50<00:00,  1.78s/it]\n","                 all       9559      11176       0.35      0.365      0.247       0.18\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     6/299     12.5G   0.03285    0.0189   0.07931        38       640: 100% 2390/2390 [1:52:05<00:00,  2.81s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 299/299 [08:54<00:00,  1.79s/it]\n","                 all       9559      11176      0.326       0.42      0.293       0.22\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     7/299     12.5G   0.03208   0.01898   0.07926        47       640:  14% 323/2390 [15:13<1:16:35,  2.22s/it]"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wZDwheGuM8g","executionInfo":{"status":"ok","timestamp":1630491668993,"user_tz":-540,"elapsed":12837934,"user":{"displayName":"이유민","photoUrl":"","userId":"14631073475001434536"}},"outputId":"34e45c44-a353-4ee0-b026-64be61562fab"},"source":["!python train.py --batch 16 --epochs 300 --data /content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml --cfg ./models/yolov5m.yaml --weights yolov5m.pt --resume /content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp10/weights/last.pt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=./models/yolov5m.yaml, data=/content/drive/MyDrive/YOLOv5/yolov5/data/coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=300, batch_size=16, imgsz=640, rect=False, resume=/content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp10/weights/last.pt, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=30\n","\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 3 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n","Resuming training from /content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp10/weights/last.pt\n","YOLOv5 🚀 v5.0-400-g50a9828 torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      5280  models.common.Focus                     [3, 48, 3]                    \n","  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n","  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n","  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n","  4                -1  6    629760  models.common.C3                        [192, 192, 6]                 \n","  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n","  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n","  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n","  8                -1  1   1476864  models.common.SPP                       [768, 768, [5, 9, 13]]        \n","  9                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n"," 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n"," 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n"," 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n"," 24      [17, 20, 23]  1    986004  models.yolo.Detect                      [239, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\n","Model Summary: 391 layers, 22018164 parameters, 22018164 gradients, 53.5 GFLOPs\n","\n","Transferred 506/506 items from /content/drive/MyDrive/YOLOv5/yolov5/runs/train/exp10/weights/last.pt\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 83 weight, 86 weight (no decay), 86 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_train_239.cache' images and labels... 38240 found, 0 missing, 0 empty, 2 corrupted: 100% 38240/38240 [00:00<?, ?it/s]\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/YOLOv5/data/images/train/A020143XX_14147.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/YOLOv5/data/images/train/B140709XX_31783.jpg: negative labels\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_train_239.cache' images and labels... 38240 found, 0 missing, 0 empty, 2 corrupted: 100% 38240/38240 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_valid_239.cache' images and labels... 9560 found, 0 missing, 0 empty, 1 corrupted: 100% 9560/9560 [00:00<?, ?it/s]\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label /content/drive/MyDrive/YOLOv5/data/images/valid/A270104XX_14916.jpg: negative labels\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/YOLOv5/image_valid_239.cache' images and labels... 9560 found, 0 missing, 0 empty, 1 corrupted: 100% 9560/9560 [00:00<?, ?it/s]\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/exp10\u001b[0m\n","Starting training for 300 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     7/299     6.69G   0.03235   0.01908   0.07747        48       640:  25% 589/2390 [3:32:44<7:01:57, 14.06s/it]Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1185, in __iter__\n","    for obj in iterable:\n","  File \"/content/drive/MyDrive/YOLOv5/yolov5/utils/datasets.py\", line 139, in __iter__\n","    yield next(self.iterator)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1186, in _next_data\n","    idx, data = self._get_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1142, in _get_data\n","    success, data = self._try_get_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 990, in _try_get_data\n","    data = self._data_queue.get(timeout=timeout)\n","  File \"/usr/lib/python3.7/queue.py\", line 179, in get\n","    self.not_empty.wait(remaining)\n","  File \"/usr/lib/python3.7/threading.py\", line 300, in wait\n","    gotit = waiter.acquire(True, timeout)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"train.py\", line 610, in <module>\n","    main(opt)\n","  File \"train.py\", line 508, in main\n","    train(opt.hyp, opt, device)\n","  File \"train.py\", line 286, in train\n","    for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n","  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1200, in __iter__\n","    self.close()\n","  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1279, in close\n","    self._decr_instances(self)\n","  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 598, in _decr_instances\n","    cls._instances.remove(instance)\n","  File \"/usr/lib/python3.7/_weakrefset.py\", line 109, in remove\n","    self.data.remove(ref(item))\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","metadata":{"id":"xzrrPMkNDH8c"},"source":[""],"execution_count":null,"outputs":[]}]}